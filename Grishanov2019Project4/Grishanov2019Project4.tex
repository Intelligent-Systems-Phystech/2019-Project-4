\documentclass[12pt,twoside]{article}
\usepackage{jmlda}	
% https://docs.google.com/document/d/1zkOK6iLzuwVahOh138aTh5FzoX_LHCWlMiGS1LnsZhA/edit
\title
%    [Автоматическая настройка параметров BigARTM ] % Краткое название; не нужно, если полное название влезает в~колонтитул
{Автоматическая настройка параметров BigARTM под широкий класс задач.}
\author
%    [Гришанов~А.\,В.] % список авторов для колонтитула; не нужен, если основной список влезает в колонтитул
{Гришанов~А.\,В., Булатов~B.\,Г., Воронцов~К.\,В.} % основной список авторов, выводимый в оглавление
[Гришанов~А.\,В.$^1$, Булатов~B.\,Г.$^1$, Воронцов~К.\,В.$^1$] % список авторов, выводимый в заголовок; не нужен, если он не отличается от основного
\thanks
%    {Работа выполнена при финансовой поддержке РФФИ, проект \No\,00-00-00000.
%   Научный руководитель:  Стрижов~В.\,В.
{Задачу поставил:  Булатов~B.\,Г.
	Консультант:  Воронцов~К.\,В.}
\email
{grishanov.av@phystech.ru, bt.uytya@gmail.com, vokov@forecsys.ru}
\organization
{$^1$ Московский физико-технический институт}%; $^2$Организация}
\abstract
{Открытая библиотека BigARTM строит тематические модели, минимизируя регуляризованное правдоподобие с помощью EM-алгоритма. Подбор оптимальных параметров индивидуален для разных текстовых коллекций и требует работы специалиста. Для автоматизации этого процесса в данной статье мы ищем набор параметров, дающий достаточно хорошие результаты на широком классе задач. Предлагается перейти от относительного задания коэффициентов регуляризации к абсолютному. Для эксперимента использовались наборы данных Victorian Era Authorship Attribution, 20 Newsgroups, МКБ-10. Модель с подобранными коэффициентами имеет качество не более чем на <X>\% хуже локально лучших моделей.
	
	\bigskip
	\textbf{Ключевые слова}: \emph {тематическое моделирование, аддитивная регуляризация тематических моделей, PLSA, BigARTM}.}
\titleEng
{JMLDA paper example: file jmlda-example.tex}
\authorEng
{Author~F.\,S.$^1$, CoAuthor~F.\,S.$^2$, Name~F.\,S.$^2$}
\organizationEng
{$^1$Organization; $^2$Organization}
\abstractEng
{This document is an example of paper prepared with \LaTeXe\
	typesetting system and style file \texttt{jmlda.sty}.
	
	\bigskip
	\textbf{Keywords}: \emph{keyword, keyword, more keywords}.}
\begin{document}
	
	\maketitle
	
	\section{Введение}
	
	Тематические модели широко используются на практике для решения задач классификации и ранжирования документов, а также для разведочного поиска\cite{Ianina2016}. Одним из продвинутых инструментов в тематическом моделировании является библиотека BigARTM~\cite{vorontsov2015bigartm}. Она предоставляет широкий выбор для настройки модели, используя обширный класс регуляризаторов. Однако на практике популярнее остаются более простые методы, такие как LDA\cite{blei2003latent}. Во многом это связано со необходимостью аккуратного подбора параметров модели.
	
	Предлагается проверить гипотезу о существовании конфигураций, хорошо работающих на широком классе задач.
	
	Текущий подход к выбору параметров описан в работе \cite{Ianina2016}. Сначала подбирается один из регуляризаторов (например декоррелирования).  Его значение находится приблизительно, затем в зависимости от цели исследуется следующий параметр или продолжает улучшаться текущий. Существенно то, что имеются различные регуляризаторы  для различных итераций. Поэтому процесс перебора последовательный: добавляется один регуляризатор, оптимизируется, затем добавляется следующий. Из-за этого для оптимизации трудно использовать продвинутые методы, такие как байесовская оптимизация. Остаётся жадный или рандомизированный поиск.
	
	При этом возможны два типа коэффициентов: абсолютные и относительные. Первые не переносятся между разными коллекциями, для них заранее трудно предположить даже порядок оптимальных значений. Вторые более универсальны, но требуют дополнительных вычислений.
	
	Цель данной работы --- исследовать процедуру подбора параметров и найти критерии, по которым можно выбирать начальные конфигурации BigARTM для широкого класса задач. Предлагается использовать относительные коэффициенты регуляризации.
	
	\section{Постановка задачи}
	
	Заданы: набор текстовых коллекций $\mathfrak{D} = \left\{D_i\right\}_{i=1}^{N}$, где каждая коллекция $D$ состоит из документов $d$, словари коллекциий текстов $W$, состоящих из термов $w$, и множества тем $T$, состоящих из тем  $t$.
	
	%	По коллекции $D$ требуется найти параметры $\varphi_{wt}$ и $\theta_{td}$ , при которых тематическая модель (1)
	%	хорошо приближает частотные оценки условных вероятностей $\hat{p}(w|d)=\frac{n_{dw}}{n_d}$. 
	
	Распределение вида $p(t|x)$ будем называть тематикой объекта x. Можно говорить о тематике документа $p(t|d)$, терма $p(t|w)$, терма в документе $p(t|d, w)$.
	Целью тематического моделирования является определение тематики документов
	и связанных с ними объектов. Также требуется находить распределения $\varphi_{wt}= p(w|t)$,
	описывающие семантику каждой темы $t$ словами естественного языка.
	
	Пусть задан критерий качества тематического моделирования $S$. Цель данной работы состоит в решении следующей задачи:
	
	\begin{equation}
	S \rightarrow \max_{\mathfrak{D}}
	\end{equation}
	
	\section{Задача тематического моделирования}
	
	Согласно формуле полной вероятности и гипотезе условной независимости:
	
	\begin{equation}\label{eq_0}
	p(w|d) = \sum\limits_{t \in T} p(w|t, d) p(t|d) = \sum\limits_{t \in T} p(w|t) p(t|d) = \sum\limits_{t \in T}\phi_{wt}\theta_{td}.
	\end{equation}
	
	Равенство (2) можно переписать в матричном виде. В левой части равенства находится известная матрица частотных оценок условных вероятностей $F=(\hat{p}(w|d))_{W \times D}$. Ставится задача разложения матрицы $F$ в произведение двух матриц $\Phi$ и $\Theta$ меньшего размера, таких, что
	\begin{gather*}
	\Phi = (\phi_{wt})_{W \times T}, \; \phi_{wt} = p(w|t)      \text{ --- матрица <<термины-темы>>}\\
	\Theta = (\theta_{td})_{T \times D}, \; \theta_{td} = p(t|d)  \text{ --- матрица <<темы-документы>>}
	\end{gather*}
	
	\begin{figure}[h]
		\includegraphics[scale=0.7]{phi_theta.jpg}
		\caption{Иллюстрация матричного разложения.}
		\label{fg:Example}
	\end{figure}
	
	Поставленная задача ($F \approx \Phi \Theta$) эквивалентна поиску матриц $\Phi$ и $\Theta$, максимизирующих следующий функционал правдоподобия:
	
	\begin{equation}\label{eq_1}
	L(\Phi, \Theta) = \sum_{d \in D} \sum_{w \in d} n_{dw} \sum_{t \in T} \phi_{wt} \theta_{td} \rightarrow \max_{\Phi, \Theta}
	\end{equation}
	
	Решение данной задачи неединственно, что порождает неоднозначность в
	выборе матриц из правой части равенства. Для решения данной проблемы, наложим
	на тематическую модель дополнительные требования. Модифицируем максимизирующий функционал:
	
	\begin{equation}
	L(\Phi, \Theta) + R(\Phi, \Theta) \rightarrow \max_{\Phi, \Theta}
	\end{equation}	
	\begin{equation}	
	R(\Phi, \Theta) = \sum_{j=1}^{n} \tau_j R_j(\Phi, \Theta)
	\end{equation}
	где $R_j(\Phi, \Theta)$ --- дополнительные требования к модели (регуляризаторы),  $\tau_j$ --- неотрицательные коэффициенты регуляризации. Полученный подход к построению тематических моделей имеет название АРТМ (аддитивная регуляризация тематических моделей).
	
	\section{Итоговая постановка}
	
	Для оценивания тематической модели используют два типа критериев качества
	
	\begin{Def}
		Внутренние критерии оценивают качество построенной модели по итоговым матрицам $\Phi$ и $\Theta$ модели.
	\end{Def}
	
	\begin{Def}
		Внешние критерии измеряют качество полученных предсказаний.
	\end{Def}
	
	Рассмотрим набор датасетов $\left\{\mathfrak{D}_{ex}, \mathfrak{D}_{in}\right\}$, где  $\mathfrak{D}_{ex} = \left\{\mathfrak{D}_j\right\}_{j=1}^{N_{ex}}$ имеют внешний критерий качества $S(\tau_j, \mathfrak{D}_j)$, а $\mathfrak{D}_{in} = \left\{\mathfrak{D}_j\right\}_{j=1}^{N_{in}}$~ --- только внутренние. Для каждого из первых найдём лучшие параметры.
	
	\begin{equation}
	\tau_{j_{best}} = \argmin_{\tau} S(\tau, \mathfrak{D}_j) ,\ j = 1,\dots , N_{ex}
	\end{equation}
	
	Необходимо проверить гипотезу о том, что существуют коэффициенты регуляризации $\tau_{general}$, которые можно считать <<универсальными>>, т.е. такие что выполнено:
	
	\begin{equation}
	\max_{j=1,\dots,N_{ex}+N_{in}} \frac{S(\tau_{j_{best}}, \mathfrak{D}_j)- S(\tau_{general}, \mathfrak{D}_j)}{S(\tau_{j_{best}}, \mathfrak{D}_j)} \leq 5\%
	\end{equation}
	
	Для поиска $\tau_{general}$ будем использовать $\mathfrak{D}_{ex}$, минимизируя следующий функционал:
	
	\begin{equation}
	\sum_{j=1}^{N_{ex}} \left(S(\tau_{j_{best}}, \mathfrak{D}_j)- S(\tau_{general}, \mathfrak{D}_j)\right)^2 \to \min
	\end{equation}
	
	Гипотезу (7) будем проверять на $\left\{\mathfrak{D}_{ex}, \mathfrak{D}_{in}\right\}$. Для этого дополнительно введём следующие определения для наборов данных с внутренними критериями качества:
	
	\begin{Def}
		Модель $X$ {\bf не хуже} чем модель $Y$, если по всем критериям $X$ хуже не более чем на $5\%$.
	\end{Def}
	
	\begin{Def}
		Модель $X$ {\bf лучше} модели $Y$ по $k$ критериям, если по этим $k$ критериям $X$ лучше $Y$ хотя бы на $5\%$.
	\end{Def}
	
	Требуется построить модель, которая {\bf не хуже} чем PLSA\cite{Hofmann:1999:PLS:2073796.2073829} и {\bf лучше} PLSA по нескольким критериям.
	
	\section{Относительные коэффициенты регуляризации}
	
	Формула M-шага, сглаживающего ($\tau > 0$) или разреживающего ($\tau < 0$) распределение
	$\varphi_{wt}$:
	
	\begin{equation}
	\varphi_{wt} = \underset{w \in W}{\text{norm}} \left(n_{wt} + \tau \right)
	\end{equation}
	
	
	Интуитивный смысл этого преобразования прост: мы либо <<притягиваем>> Фи к равномерному распределению $\beta = \frac{1}{|W|}$, либо ”отталкиваем” её от него же (возможно, даже
	зануляя при этом какие-то компоненты).
	Оказывается, можно провести репараметризацию, которая строго это продемонстрирует.
	
	Пусть $\beta = \frac{1}{|W|}$ — равномерное распределение, а текущие значения $n_{wt}$ и $\tau \in \mathbb {R}$ таковы, что на этой итерации M-шага зануления компонент не происходит (то есть либо $\tau > 0$,
	либо $\tau < 0$, но $n_{wt} + \tau > 0$).
	Тогда операцию положительной обрезки можно проигнорировать:
	\begin{equation}
	\varphi_{wt} = \underset{w \in W}{\text{norm}} \left(n_{wt} + \tau \right) = \frac{n_{wt} + \tau}{\sum\limits_{w \in W} n_{wt} + \tau} = \frac{n_{wt} + \tau}{n_{t} + \tau |W|}
	\end{equation}
	
	представим это выражение, как выпуклую комбинацию распределений $\frac{n_{wt}}
	{n_t}$ (оценки максимума правдоподобия) и $\frac{1}{|W|}$ (равномерного распределения)
	
	\begin{equation}
	\frac{n_{wt} + \tau}{n_{t} + \tau |W|} = (1 - \lambda)\frac{n_{wt}}{n_t} + \lambda \frac{1}{|W|} 
	\Rightarrow	
	\tau = \frac{n_t\lambda}{(1 - \lambda)|W|}
	\end{equation}
	
	Значит, сглаживание Фи можно трактовать, как нахождение компромисса между $\varphi_{wt}$~=~$\frac{n_{wt}}
	{n_t}$ и $\varphi_{wt} = \frac{1}{|W|}$.
	
	Допустим, мы хотим провести регуляризацию так, чтобы $\varphi_{wt}$ на 50\% состояла из оценки максимума правдоподобия, и на 50\% из априорного
	распределения $\frac{1}{|W|}$. Для этого достаточно вычислить $\tau$ по формуле и подставить в модель.
	
	%\subsection{Используемые регуляризаторы} \label{subsec:coefs}
	%
	%Будем использовать следующие 5 регуляризаторов:
	%
	%\begin{enumerate}
	%	
	%	\item 
	%	Сглаживание распределений терминов в темах. 
	%	
	%	Используется для выделения фоновых тем, собирающих общую лексику языка или общую лексику данной коллекции.
	%	
	%	\item 
	%	Сглаживание распределений тем в документах. 
	%	
	%	Используется для выделения фоновых слов в каждом документах.
	%	
	%	\item 
	%	Разреживание распределений терминов в темах. 
	%	
	%	Используется для выделения лексических ядер предметных тем как относительно небольшой доли слов словаря.
	%	
	%	\item 
	%	Разреживание распределений тем в документах. 
	%	
	%	Используется для выделения относительно небольшой доли предметных тем в каждом документах.
	%	
	%	\item 
	%	Декоррелирование распределений терминов в темах. 
	%	
	%	Используется для повышения различности лексических ядер предметных тем.
	%	
	%\end{enumerate}
	
	%\begin{State}
	%    Мотивации и~интерпретации наиболее важны для понимания сути работы.
	%\end{State}
	
	%\begin{Theorem}
	%    Не~менее $90\%$ коллег, заинтересовавшихся Вашей статьёй,
	%    прочитают в~ней не~более~$10\%$ текста.
	%\end{Theorem}
	%
	%\begin{Proof}
	%    Причём это будут именно те~разделы, которые не содержат формул.
	%\end{Proof}
	%
	%\begin{Remark}
	%    Выше показано применение окружений
	%    Def, Theorem, State, Remark, Proof.
	%\end{Remark}
	
	
	%\section{Заключение}
	
	%Желательно, чтобы этот раздел был, причём он не~должен дословно повторять аннотацию.
	%Обычно здесь отмечают,
	%каких результатов удалось добиться,
	%какие проблемы остались открытыми.
	
	
	\bibliographystyle{plain}
	\bibliography{Grishanov2019Project4}
	%\begin{thebibliography}{1}
	%
	%\bibitem{author09anyscience}
	%    \BibAuthor{Author\;N.}
	%    \BibTitle{Paper title}~//
	%    \BibJournal{10-th Int'l. Conf. on Anyscience}, 2009.  Vol.\,11, No.\,1.  Pp.\,111--122.
	%\bibitem{myHandbook}
	%    \BibAuthor{Автор\;И.\,О.}
	%    Название книги.
	%    Город: Издательство, 2009. 314~с.
	%\bibitem{author-and-co2007}
	%    \BibAuthor{Автор\;И.\,О., Соавтор\;И.\,О.}
	%    \BibTitle{Название статьи}~//
	%    \BibJournal{Название журнала}. 2007. Т.\,38, \No\,5. С.\,54--62.
	%\bibitem{bibUsefulUrl}
	%    \BibUrl{www.site.ru}~---
	%    Название сайта.  2007.
	%\end{thebibliography}
	
	% Решение Программного Комитета:
	%\ACCEPTNOTE
	%\AMENDNOTE
	%\REJECTNOTE
\end{document}
